{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime \n",
    "import musicbrainzngs as music\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/Users/benstager/Desktop/rock riddle/backend/\")\n",
    "\n",
    "music.set_useragent(\"Rock-Riddle\", \"1.0\", \"bstager@tulane.edu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'backend/ALBUMS.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m album_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbackend/ALBUMS.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'backend/ALBUMS.csv'"
     ]
    }
   ],
   "source": [
    "album_df = pd.read_csv('backend/ALBUMS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['High Voltage',\n",
       " 'T.N.T.',\n",
       " 'Dirty Deeds Done Dirt Cheap',\n",
       " 'Let There Be Rock',\n",
       " 'Powerage',\n",
       " 'Highway to Hell',\n",
       " 'Back in Black',\n",
       " 'For Those About to Rock (We Salute You)',\n",
       " 'Flick of the Switch',\n",
       " 'Fly on the Wall',\n",
       " 'Blow Up Your Video',\n",
       " 'The Razors Edge',\n",
       " 'Ballbreaker',\n",
       " 'Stiff Upper Lip',\n",
       " 'Black Ice',\n",
       " 'Rock or Bust',\n",
       " 'Power Up',\n",
       " 'High Voltage',\n",
       " 'Double Dynamite 2 Originals',\n",
       " '3 Record Set',\n",
       " 'Rock and Roll Ain’t Noise Pollution',\n",
       " 'Vol. 1',\n",
       " 'For Those About to Rock',\n",
       " 'Vol. 2',\n",
       " 'The Early Years']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.literal_eval(album_df['albums'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_bands = [\n",
    "    \"38 Special\", \"A Flock of Seagulls\", \"Accept\", \"Adrian Belew\", \"Aldo Nova\", \"Alphaville\", \"Ambrosia\", \n",
    "    \"Angel\", \"April Wine\", \"Argent\", \"Atomic Rooster\", \"Babyshambles\", \"Bananarama\", \"Barclay James Harvest\", \n",
    "    \"Big Audio Dynamite\", \"Black Oak Arkansas\", \"Blodwyn Pig\", \"Bloodrock\", \"Bonzo Dog Doo-Dah Band\", \n",
    "    \"Booker T. & the M.G.'s\", \"Brownsville Station\", \"Budgie\", \"Captain Beefheart\", \"Canned Heat\", \n",
    "    \"Chicory Tip\", \"City Boy\", \"Climax Blues Band\", \"Conway Twitty\", \"Country Joe and the Fish\", \n",
    "    \"Crack the Sky\", \"Crazy Horse\", \"Cursive\", \"David Crosby\", \"Dennis DeYoung\", \"Devil Doll\", \n",
    "    \"Diesel\", \"Dr. Feelgood\", \"Electric Prunes\", \"Elvis Costello and the Attractions\", \"Eric Burdon\", \n",
    "    \"Family\", \"Fanny\", \"Focus\", \"Foghat\", \"Franz Ferdinand\", \"Giant Sand\", \"Golden Earring\", \n",
    "    \"Graham Parker\", \"Green On Red\", \"Gypsy\", \"Haircut One Hundred\", \"Hawkwind\", \"Head East\", \n",
    "    \"Heaven 17\", \"Herman's Hermits\", \"Ian Dury\", \"It Bites\", \"Jefferson Starship\", \"Jo Jo Gunne\", \n",
    "    \"Johnny Hates Jazz\", \"Johnny Winter\", \"Kayak\", \"Klaatu\", \"Krokus\", \"Lighthouse\", \"Little River Band\", \n",
    "    \"Long John Baldry\", \"Love Sculpture\", \"Magazine\", \"Mahogany Rush\", \"Man\", \"Manic Street Preachers\", \n",
    "    \"Marble Arch\", \"Max Webster\", \"MC5\", \"Moby Grape\", \"Morcheeba\", \"Mother Love Bone\", \n",
    "    \"Murray Head\", \"Nantucket\", \"Nash the Slash\", \"Nazareth\", \"Nektar\", \"Nils Lofgren\", \n",
    "    \"Norman Greenbaum\", \"Outlaws\", \"Ozzy Osbourne\", \"Pale Saints\", \"Paul Revere & the Raiders\", \n",
    "    \"Pentangle\", \"Peter Green\", \"Pigbag\", \"Player\", \"Point Blank\", \"Poco\", \"Porcupine Tree\", \n",
    "    \"Portishead\", \"Pretty Things\", \"Quicksilver Messenger Service\", \"Renaissance\", \"Riot\", \n",
    "    \"Riverside\", \"Ritchie Blackmore's Rainbow\", \"Robin Trower\", \"Roger Hodgson\", \"Rory Gallagher\", \n",
    "    \"Screaming Jets\", \"Sensational Alex Harvey Band\", \"Severed Heads\", \"Shooting Star\", \"Shriekback\", \n",
    "    \"Siren\", \"Soft Machine\", \"Southside Johnny & the Asbury Jukes\", \"Spiral Starecase\", \"Spirit\", \n",
    "    \"Spooky Tooth\", \"Stackridge\", \"Stan Ridgway\", \"Starcastle\", \"Starsailor\", \"Steeleye Span\", \n",
    "    \"Strawbs\", \"Streetheart\", \"Strife\", \"Suede\", \"Super Furry Animals\", \"Swervedriver\", \n",
    "    \"Sweet\", \"Tangerine Dream\", \"Tavares\", \"Taxxi\", \"Ten Years After\", \"The Alarm\", \"The Amboy Dukes\", \n",
    "    \"The Band\", \"The Big Dish\", \"The Cramps\", \"The Cryan' Shames\", \"The Dictators\", \n",
    "    \"The Fugs\", \"The Hollies\", \"The Incredible String Band\", \"The Jayhawks\", \"The Knack\", \n",
    "    \"The La's\", \"The Mars Volta\", \"The Nice\", \"The Psychedelic Furs\", \"The Saints\", \n",
    "    \"The Shadows\", \"The Spencer Davis Group\", \"The Stooges\", \"The Tea Party\", \"The The\", \n",
    "    \"The Turtles\", \"The Vapors\", \"The Yardbirds\", \"Thin White Rope\", \"Thunderclap Newman\", \n",
    "    \"Tommy Tutone\", \"Tony Joe White\", \"Traffic\", \"Triumph\", \"Trooper\", \"U.K.\", \"Ultimate Spinach\", \n",
    "    \"Vanilla Fudge\", \"Wall of Voodoo\", \"Wanda Jackson\", \"Wang Chung\", \"Wet Willie\", \"Wishbone Ash\", \n",
    "    \"Wolfmother\", \"X-Ray Spex\", \"Y&T\", \"Yellow Magic Orchestra\", \"Zebra\", \"Zero 7\", \n",
    "    \"Ziggy Marley\", \"Zounds\", \"Zwan\", \"Autograph\", \"Baltimora\", \"Barenaked Ladies\", \n",
    "    \"Be Bop Deluxe\", \"Bill Bruford\", \"Billy Thorpe\", \"Blitzen Trapper\", \"Blue Cheer\", \n",
    "    \"Blue Mink\", \"Boomtown Rats\", \"Brendan Benson\", \"Bruce Hornsby\", \"Calexico\", \"Chris Isaak\", \n",
    "    \"Clannad\", \"Commander Cody and His Lost Planet Airmen\", \"Coven\", \"Crack the Sky\", \n",
    "    \"Crosby & Nash\", \"Damnation of Adam Blessing\", \"Dan Hicks\", \"Danny Kirwan\", \"David Lindley\", \n",
    "    \"David Sylvian\", \"Delaney & Bonnie\", \"Dixie Dregs\", \"Donovan\", \"Doug Sahm\", \"Dr. Hook\", \n",
    "    \"Earth Opera\", \"Emitt Rhodes\", \"England Dan & John Ford Coley\", \"Fairport Convention\", \n",
    "    \"Flying Burrito Brothers\", \"Fotheringay\", \"Gabriel Bondage\", \"Gentle Giant\", \n",
    "    \"Gerry Rafferty\", \"Godley & Creme\", \"Gordon Lightfoot\", \"Grand Funk Railroad\", \n",
    "    \"Hedgehoppers Anonymous\", \"Horace Silver\", \"Ian Hunter\", \"Iggy Pop\", \"Jellyfish\", \n",
    "    \"John Cale\", \"John Mayall's Bluesbreakers\", \"Johnny Thunder\", \"Jon and Vangelis\", \n",
    "    \"Junior's Eyes\", \"Keef Hartley Band\", \"Kevin Ayers\", \"Laurie Anderson\", \"Leo Kottke\", \n",
    "    \"Leslie West\", \"Lindisfarne\", \"Loggins and Messina\", \"Marc Bolan\", \"Matching Mole\", \n",
    "    \"Michael Nesmith\", \"Mike Oldfield\", \"Minutemen\", \"Moby Grape\", \"Neil Innes\", \n",
    "    \"Nico\", \"Nick Drake\", \"NRBQ\", \"Os Mutantes\", \"Pavlov's Dog\", \"Pentangle\", \n",
    "    \"Peter Gabriel\", \"Peter, Paul and Mary\", \"Procol Harum\", \"Quintessence\", \n",
    "    \"Robin Williamson\", \"Roger Waters\", \"Sandy Denny\", \"Savoy Brown\", \"Seatrain\", \n",
    "    \"Shane MacGowan\", \"Sky\", \"Soft Boys\", \"Sons of Champlin\", \"Spirit\", \"Stackridge\", \n",
    "    \"Steeleye Span\", \"Steve Hackett\", \"Steve Hillage\", \"String Driven Thing\", \"T. Rex\", \n",
    "    \"Television\", \"The Band\", \"The Chambers Brothers\", \"The Dead Boys\", \"The Electric Flag\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cleaned_artist(artist_name):\n",
    "    try:\n",
    "        artist_high_level = music.get_artist_by_id(music.search_artists(artist= artist_name)['artist-list'][0]['id'])['artist']\n",
    "        first_albums = music.browse_release_groups(music.search_artists(artist=artist_name)['artist-list'][0]['id'], release_type=[\"album\"])['release-group-list']\n",
    "        try:\n",
    "            start_band_date = music.search_artists(artist=artist_name)['artist-list'][0]['life-span']['begin']\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "        name = artist_name\n",
    "        begin_date = pd.Timestamp(start_band_date).date()\n",
    "        area = artist_high_level['area']['name']\n",
    "        albums = []\n",
    "\n",
    "        album_name = []\n",
    "        release_date = []\n",
    "\n",
    "        for album in first_albums:\n",
    "            if len(album['first-release-date']) > 0:\n",
    "                album_name.append(album['title'])\n",
    "                release_date.append(album['first-release-date'])\n",
    "            \n",
    "        \n",
    "        date_name_frame = pd.DataFrame({'albums':album_name, 'date':release_date}).sort_values('date')\n",
    "        first_four_years = date_name_frame['date'].apply(lambda x: pd.Timestamp(x).date()).values[:4]\n",
    "\n",
    "        final_dict = {\n",
    "            'name':artist_name,\n",
    "            'form_date':begin_date,\n",
    "            'location':area,\n",
    "            'release_1':first_four_years[0],\n",
    "            'release_2':first_four_years[1],\n",
    "            'release_3':first_four_years[2],\n",
    "            'release_4':first_four_years[3]\n",
    "        }\n",
    "\n",
    "        return pd.DataFrame(final_dict,index=[0])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'FAILED: {artist_name}, {e}')\n",
    "        return None\n",
    "\n",
    "def create_album_dict(artist_name):\n",
    "    try:\n",
    "        artist_high_level = music.get_artist_by_id(music.search_artists(artist= artist_name)['artist-list'][0]['id'])['artist']\n",
    "        first_albums = music.browse_release_groups(music.search_artists(artist=artist_name)['artist-list'][0]['id'], release_type=[\"album\"])['release-group-list']\n",
    "        start_band_date = music.search_artists(artist=artist_name)['artist-list'][0]['life-span']['begin']\n",
    "\n",
    "        name = artist_name\n",
    "        begin_date = pd.Timestamp(start_band_date).date()\n",
    "        area = artist_high_level['area']['name']\n",
    "\n",
    "        album_name = []\n",
    "        release_date = []\n",
    "\n",
    "        for album in first_albums:\n",
    "            album_name.append(album['title'])\n",
    "            release_date.append(album['first-release-date'])\n",
    "\n",
    "        album_name = [i for i in album_name if artist_name not in i]\n",
    "        albums = {artist_name:album_name}\n",
    "\n",
    "        return albums\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'FAILED: {artist_name}, {e}')\n",
    "        return None\n",
    "\n",
    "# this needs to point to csv's\n",
    "def update_backend(n_updates=5):\n",
    "    try:\n",
    "        data = pd.read_csv('band_unit_test.csv')\n",
    "        current_bands = data['name'].unique()\n",
    "        bands_to_update = np.setdiff1d(additional_bands, current_bands)[:n_updates]\n",
    "\n",
    "        bands_cleaned = [create_cleaned_artist(artist_name=artist) for artist in bands_to_update]\n",
    "        bands_cleaned = [i for i in bands_cleaned if i is not None]\n",
    "        cleaned_data = pd.concat([create_cleaned_artist(artist_name=artist) for artist in bands_to_update])\n",
    "        update = pd.concat([data, cleaned_data])\n",
    "        update.to_csv('BANDS.csv')\n",
    "\n",
    "        albums_update = {}\n",
    "        for artist in current_bands:\n",
    "            albums_update.update(create_album_dict(artist_name=artist))\n",
    "        \n",
    "        album_name_dict.update(albums_update)\n",
    "        \n",
    "        with open(\"app_data.py\", \"a\") as file:\n",
    "            file.write(f\"\\nmy_dict = {album_name_dict}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"BACKEND UPDATE FAILED: {e}\")\n",
    "        \n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'38 Special': ['Special Delivery',\n",
       "  'Rockin’ Into the Night',\n",
       "  'Wild‐Eyed Southern Boys',\n",
       "  'Special Forces',\n",
       "  'Tour de Force',\n",
       "  'Strength in Numbers',\n",
       "  'Rock & Roll Strategy',\n",
       "  'Bone Against Steel',\n",
       "  'Resolution',\n",
       "  'A Wild‐Eyed Christmas Night',\n",
       "  'Drivetrain',\n",
       "  '10 From 38',\n",
       "  'Flashback',\n",
       "  'Anthology',\n",
       "  'Christmas',\n",
       "  'The Very Best of the A&M Years (1977–1988)',\n",
       "  'Best Shots',\n",
       "  'Icon',\n",
       "  'Classics',\n",
       "  'Greatest Hits',\n",
       "  'Wild Eyed and Live!',\n",
       "  'Live at Sturgis',\n",
       "  'Extended Versions: The Encore Collection']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_album_dict(artist_name=additional_bands[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating rng dict to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_day = pd.DataFrame({\n",
    "    'date':list(rng_dict.keys()),\n",
    "    'idx':list(rng_dict.values())\n",
    "})\n",
    "\n",
    "reset_day.to_csv('~/Desktop/rock riddle/DAY_RESET.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_df = pd.DataFrame({\n",
    "    'artist': list(album_name_dict.keys()),\n",
    "    'albums': list(album_name_dict.values())\n",
    "})\n",
    "\n",
    "album_df.to_csv('~/Desktop/rock riddle/ALBUMS.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_backend(n_updates=5):\n",
    "    try:\n",
    "        # 1. update bands\n",
    "        data = pd.read_csv('band_unit_test.csv')\n",
    "        current_bands = data['name'].unique()\n",
    "        bands_to_update = np.setdiff1d(additional_bands, current_bands)[:n_updates]\n",
    "\n",
    "        bands_cleaned = [create_cleaned_artist(artist_name=artist) for artist in bands_to_update]\n",
    "        bands_cleaned = pd.concat([i for i in bands_cleaned if i is not None])\n",
    "        cleaned_artists = bands_cleaned['name'].unique()\n",
    "\n",
    "        update = pd.concat([data, bands_cleaned])\n",
    "        update.to_csv('~/Desktop/rock riddle/BANDS.csv', index=False)\n",
    "        \n",
    "        # 2. update albums\n",
    "        albums_existing = pd.read_csv('~/Desktop/rock riddle/backend/ALBUMS.csv')\n",
    "        album_frames = []\n",
    "        for artist in cleaned_artists:\n",
    "            try:\n",
    "                album_data = create_album_dict(artist_name=artist)\n",
    "                album_frame = pd.DataFrame({\n",
    "                    'artist': list(album_data.keys())[0],\n",
    "                    'albums': list(album_data.values())\n",
    "                })\n",
    "            except:\n",
    "                album_frame = None\n",
    "            \n",
    "            album_frames.append(album_frame)\n",
    "        \n",
    "        album_frames = pd.concat([frame for frame in album_frames if frame is not None])\n",
    "\n",
    "        albums_final = pd.concat([albums_existing, album_frames])\n",
    "        albums_final.to_csv('~/Desktop/rock riddle/backend/ALBUMS.csv', index=False)\n",
    "\n",
    "        # 3. update day indices \n",
    "        existing_days = pd.read_csv('~/Desktop/rock riddle/backend/DAY_RESET.csv')\n",
    "        final_day = existing_days['date'].values[-1]\n",
    "        range_dates = pd.date_range(\n",
    "            start=(pd.Timestamp(final_day).date() + pd.DateOffset(days=1)), end=(pd.Timestamp(final_day).date() + pd.DateOffset(days=album_frames.shape[0])).date(), freq='D')\n",
    "        \n",
    "        arr = np.array(range(existing_days.shape[0] + 1, existing_days.shape[0] + album_frames.shape[0] + 1))\n",
    "\n",
    "        np.random.shuffle(arr)\n",
    "\n",
    "        new_days = pd.DataFrame({\n",
    "            'date': [str(date.date()) for date in range_dates],\n",
    "            'idx': arr\n",
    "        })\n",
    "\n",
    "        final_days = pd.concat([existing_days, new_days])\n",
    "\n",
    "        final_days.to_csv('~/Desktop/rock riddle/backend/DAY_RESET.csv', index=False)\n",
    "\n",
    "        return final_days.sort_values('date')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"BACKEND UPDATE FAILED: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('~/Desktop/rock riddle/backend/DAY_RESET.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-26</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-08-18</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-08-19</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-08-20</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-08-21</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-08-22</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  idx\n",
       "0   2024-12-25   95\n",
       "1   2024-12-26   61\n",
       "2   2024-12-27  113\n",
       "3   2024-12-28    4\n",
       "4   2024-12-29   10\n",
       "..         ...  ...\n",
       "0   2025-08-18  239\n",
       "1   2025-08-19  241\n",
       "2   2025-08-20  240\n",
       "3   2025-08-21  237\n",
       "4   2025-08-22  238\n",
       "\n",
       "[241 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249,\n",
       "       250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262,\n",
       "       263, 264, 265, 266])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-08-17'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2025-08-18', '2025-08-19', '2025-08-20', '2025-08-21',\n",
       "               '2025-08-22', '2025-08-23', '2025-08-24', '2025-08-25',\n",
       "               '2025-08-26', '2025-08-27', '2025-08-28', '2025-08-29',\n",
       "               '2025-08-30', '2025-08-31', '2025-09-01', '2025-09-02',\n",
       "               '2025-09-03', '2025-09-04', '2025-09-05', '2025-09-06',\n",
       "               '2025-09-07', '2025-09-08', '2025-09-09', '2025-09-10',\n",
       "               '2025-09-11', '2025-09-12', '2025-09-13', '2025-09-14',\n",
       "               '2025-09-15', '2025-09-16', '2025-09-17', '2025-09-18',\n",
       "               '2025-09-19', '2025-09-20', '2025-09-21', '2025-09-22',\n",
       "               '2025-09-23', '2025-09-24', '2025-09-25', '2025-09-26',\n",
       "               '2025-09-27', '2025-09-28', '2025-09-29', '2025-09-30',\n",
       "               '2025-10-01'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_day = test['date'].values[-1]\n",
    "pd.date_range(start=(pd.Timestamp(final_day).date() + pd.DateOffset(days=1)), end=(pd.Timestamp(final_day).date() + pd.DateOffset(days=45)).date(), freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_country_dict = {\n",
    "    'Australia':'Australia',\n",
    "    'United States':'North America',\n",
    "    'United Kingdom':'Europe',\n",
    "    'England':'Europe',\n",
    "    'Canada':'North America',\n",
    "    'Germany':'Europe',\n",
    "    'Ireland':'Europe',\n",
    "    'Memphis':'North America',\n",
    "    'Netherlands':'Europe',\n",
    "    'Finland':'Europe',\n",
    "    'Brazil':'South America',\n",
    "    'Jamaica':'North America',\n",
    "    'Sweden':'Europe',\n",
    "    'New York':'North America',\n",
    "    'Boston':'North America'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = pd.DataFrame({\n",
    "    'country': list(full_country_dict.keys()),\n",
    "    'continents': list(full_country_dict.values())\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df.to_csv('/Users/benstager/Desktop/rock riddle/backend/COUNTRIES.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
