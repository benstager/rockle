{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime \n",
    "import musicbrainzngs as music\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/Users/benstager/Desktop/rock riddle/backend/\")\n",
    "\n",
    "music.set_useragent(\"Rock-Riddle\", \"1.0\", \"bstager@tulane.edu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_df = pd.read_csv('/Users/benstager/Desktop/rock riddle/backend/ALBUMS.csv')\n",
    "album_name_dict = {i:j for i,j in zip(album_df['artist'], album_df['albums'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['High Voltage',\n",
       " 'T.N.T.',\n",
       " 'Dirty Deeds Done Dirt Cheap',\n",
       " 'Let There Be Rock',\n",
       " 'Powerage',\n",
       " 'Highway to Hell',\n",
       " 'Back in Black',\n",
       " 'For Those About to Rock (We Salute You)',\n",
       " 'Flick of the Switch',\n",
       " 'Fly on the Wall',\n",
       " 'Blow Up Your Video',\n",
       " 'The Razors Edge',\n",
       " 'Ballbreaker',\n",
       " 'Stiff Upper Lip',\n",
       " 'Black Ice',\n",
       " 'Rock or Bust',\n",
       " 'Power Up',\n",
       " 'High Voltage',\n",
       " 'Double Dynamite 2 Originals',\n",
       " '3 Record Set',\n",
       " 'Rock and Roll Ain’t Noise Pollution',\n",
       " 'Vol. 1',\n",
       " 'For Those About to Rock',\n",
       " 'Vol. 2',\n",
       " 'The Early Years']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.literal_eval(album_df['albums'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_bands = [\n",
    "    \"38 Special\", \"A Flock of Seagulls\", \"Accept\", \"Adrian Belew\", \"Aldo Nova\", \"Alphaville\", \"Ambrosia\", \n",
    "    \"Angel\", \"April Wine\", \"Argent\", \"Atomic Rooster\", \"Babyshambles\", \"Bananarama\", \"Barclay James Harvest\", \n",
    "    \"Big Audio Dynamite\", \"Black Oak Arkansas\", \"Blodwyn Pig\", \"Bloodrock\", \"Bonzo Dog Doo-Dah Band\", \n",
    "    \"Booker T. & the M.G.'s\", \"Brownsville Station\", \"Budgie\", \"Captain Beefheart\", \"Canned Heat\", \n",
    "    \"Chicory Tip\", \"City Boy\", \"Climax Blues Band\", \"Conway Twitty\", \"Country Joe and the Fish\", \n",
    "    \"Crack the Sky\", \"Crazy Horse\", \"Cursive\", \"David Crosby\", \"Dennis DeYoung\", \"Devil Doll\", \n",
    "    \"Diesel\", \"Dr. Feelgood\", \"Electric Prunes\", \"Elvis Costello and the Attractions\", \"Eric Burdon\", \n",
    "    \"Family\", \"Fanny\", \"Focus\", \"Foghat\", \"Franz Ferdinand\", \"Giant Sand\", \"Golden Earring\", \n",
    "    \"Graham Parker\", \"Green On Red\", \"Gypsy\", \"Haircut One Hundred\", \"Hawkwind\", \"Head East\", \n",
    "    \"Heaven 17\", \"Herman's Hermits\", \"Ian Dury\", \"It Bites\", \"Jefferson Starship\", \"Jo Jo Gunne\", \n",
    "    \"Johnny Hates Jazz\", \"Johnny Winter\", \"Kayak\", \"Klaatu\", \"Krokus\", \"Lighthouse\", \"Little River Band\", \n",
    "    \"Long John Baldry\", \"Love Sculpture\", \"Magazine\", \"Mahogany Rush\", \"Man\", \"Manic Street Preachers\", \n",
    "    \"Marble Arch\", \"Max Webster\", \"MC5\", \"Moby Grape\", \"Morcheeba\", \"Mother Love Bone\", \n",
    "    \"Murray Head\", \"Nantucket\", \"Nash the Slash\", \"Nazareth\", \"Nektar\", \"Nils Lofgren\", \n",
    "    \"Norman Greenbaum\", \"Outlaws\", \"Ozzy Osbourne\", \"Pale Saints\", \"Paul Revere & the Raiders\", \n",
    "    \"Pentangle\", \"Peter Green\", \"Pigbag\", \"Player\", \"Point Blank\", \"Poco\", \"Porcupine Tree\", \n",
    "    \"Portishead\", \"Pretty Things\", \"Quicksilver Messenger Service\", \"Renaissance\", \"Riot\", \n",
    "    \"Riverside\", \"Ritchie Blackmore's Rainbow\", \"Robin Trower\", \"Roger Hodgson\", \"Rory Gallagher\", \n",
    "    \"Screaming Jets\", \"Sensational Alex Harvey Band\", \"Severed Heads\", \"Shooting Star\", \"Shriekback\", \n",
    "    \"Siren\", \"Soft Machine\", \"Southside Johnny & the Asbury Jukes\", \"Spiral Starecase\", \"Spirit\", \n",
    "    \"Spooky Tooth\", \"Stackridge\", \"Stan Ridgway\", \"Starcastle\", \"Starsailor\", \"Steeleye Span\", \n",
    "    \"Strawbs\", \"Streetheart\", \"Strife\", \"Suede\", \"Super Furry Animals\", \"Swervedriver\", \n",
    "    \"Sweet\", \"Tangerine Dream\", \"Tavares\", \"Taxxi\", \"Ten Years After\", \"The Alarm\", \"The Amboy Dukes\", \n",
    "    \"The Band\", \"The Big Dish\", \"The Cramps\", \"The Cryan' Shames\", \"The Dictators\", \n",
    "    \"The Fugs\", \"The Hollies\", \"The Incredible String Band\", \"The Jayhawks\", \"The Knack\", \n",
    "    \"The La's\", \"The Mars Volta\", \"The Nice\", \"The Psychedelic Furs\", \"The Saints\", \n",
    "    \"The Shadows\", \"The Spencer Davis Group\", \"The Stooges\", \"The Tea Party\", \"The The\", \n",
    "    \"The Turtles\", \"The Vapors\", \"The Yardbirds\", \"Thin White Rope\", \"Thunderclap Newman\", \n",
    "    \"Tommy Tutone\", \"Tony Joe White\", \"Traffic\", \"Triumph\", \"Trooper\", \"U.K.\", \"Ultimate Spinach\", \n",
    "    \"Vanilla Fudge\", \"Wall of Voodoo\", \"Wanda Jackson\", \"Wang Chung\", \"Wet Willie\", \"Wishbone Ash\", \n",
    "    \"Wolfmother\", \"X-Ray Spex\", \"Y&T\", \"Yellow Magic Orchestra\", \"Zebra\", \"Zero 7\", \n",
    "    \"Ziggy Marley\", \"Zounds\", \"Zwan\", \"Autograph\", \"Baltimora\", \"Barenaked Ladies\", \n",
    "    \"Be Bop Deluxe\", \"Bill Bruford\", \"Billy Thorpe\", \"Blitzen Trapper\", \"Blue Cheer\", \n",
    "    \"Blue Mink\", \"Boomtown Rats\", \"Brendan Benson\", \"Bruce Hornsby\", \"Calexico\", \"Chris Isaak\", \n",
    "    \"Clannad\", \"Commander Cody and His Lost Planet Airmen\", \"Coven\", \"Crack the Sky\", \n",
    "    \"Crosby & Nash\", \"Damnation of Adam Blessing\", \"Dan Hicks\", \"Danny Kirwan\", \"David Lindley\", \n",
    "    \"David Sylvian\", \"Delaney & Bonnie\", \"Dixie Dregs\", \"Donovan\", \"Doug Sahm\", \"Dr. Hook\", \n",
    "    \"Earth Opera\", \"Emitt Rhodes\", \"England Dan & John Ford Coley\", \"Fairport Convention\", \n",
    "    \"Flying Burrito Brothers\", \"Fotheringay\", \"Gabriel Bondage\", \"Gentle Giant\", \n",
    "    \"Gerry Rafferty\", \"Godley & Creme\", \"Gordon Lightfoot\", \"Grand Funk Railroad\", \n",
    "    \"Hedgehoppers Anonymous\", \"Horace Silver\", \"Ian Hunter\", \"Iggy Pop\", \"Jellyfish\", \n",
    "    \"John Cale\", \"John Mayall's Bluesbreakers\", \"Johnny Thunder\", \"Jon and Vangelis\", \n",
    "    \"Junior's Eyes\", \"Keef Hartley Band\", \"Kevin Ayers\", \"Laurie Anderson\", \"Leo Kottke\", \n",
    "    \"Leslie West\", \"Lindisfarne\", \"Loggins and Messina\", \"Marc Bolan\", \"Matching Mole\", \n",
    "    \"Michael Nesmith\", \"Mike Oldfield\", \"Minutemen\", \"Moby Grape\", \"Neil Innes\", \n",
    "    \"Nico\", \"Nick Drake\", \"NRBQ\", \"Os Mutantes\", \"Pavlov's Dog\", \"Pentangle\", \n",
    "    \"Peter Gabriel\", \"Peter, Paul and Mary\", \"Procol Harum\", \"Quintessence\", \n",
    "    \"Robin Williamson\", \"Roger Waters\", \"Sandy Denny\", \"Savoy Brown\", \"Seatrain\", \n",
    "    \"Shane MacGowan\", \"Sky\", \"Soft Boys\", \"Sons of Champlin\", \"Spirit\", \"Stackridge\", \n",
    "    \"Steeleye Span\", \"Steve Hackett\", \"Steve Hillage\", \"String Driven Thing\", \"T. Rex\", \n",
    "    \"Television\", \"The Band\", \"The Chambers Brothers\", \"The Dead Boys\", \"The Electric Flag\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cleaned_artist(artist_name):\n",
    "    try:\n",
    "        artist_high_level = music.get_artist_by_id(music.search_artists(artist= artist_name)['artist-list'][0]['id'])['artist']\n",
    "        first_albums = music.browse_release_groups(music.search_artists(artist=artist_name)['artist-list'][0]['id'], release_type=[\"album\"])['release-group-list']\n",
    "        try:\n",
    "            start_band_date = music.search_artists(artist=artist_name)['artist-list'][0]['life-span']['begin']\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "        name = artist_name\n",
    "        begin_date = pd.Timestamp(start_band_date).date()\n",
    "        area = artist_high_level['area']['name']\n",
    "        albums = []\n",
    "\n",
    "        album_name = []\n",
    "        release_date = []\n",
    "\n",
    "        for album in first_albums:\n",
    "            if len(album['first-release-date']) > 0:\n",
    "                album_name.append(album['title'])\n",
    "                release_date.append(album['first-release-date'])\n",
    "            \n",
    "        \n",
    "        date_name_frame = pd.DataFrame({'albums':album_name, 'date':release_date}).sort_values('date')\n",
    "        first_four_years = date_name_frame['date'].apply(lambda x: pd.Timestamp(x).date()).values[:4]\n",
    "\n",
    "        final_dict = {\n",
    "            'name':artist_name,\n",
    "            'form_date':begin_date,\n",
    "            'location':area,\n",
    "            'release_1':first_four_years[0],\n",
    "            'release_2':first_four_years[1],\n",
    "            'release_3':first_four_years[2],\n",
    "            'release_4':first_four_years[3]\n",
    "        }\n",
    "\n",
    "        return pd.DataFrame(final_dict,index=[0])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'FAILED: {artist_name}, {e}')\n",
    "        return None\n",
    "\n",
    "def create_album_dict(artist_name):\n",
    "    try:\n",
    "        artist_high_level = music.get_artist_by_id(music.search_artists(artist= artist_name)['artist-list'][0]['id'])['artist']\n",
    "        first_albums = music.browse_release_groups(music.search_artists(artist=artist_name)['artist-list'][0]['id'], release_type=[\"album\"])['release-group-list']\n",
    "        start_band_date = music.search_artists(artist=artist_name)['artist-list'][0]['life-span']['begin']\n",
    "\n",
    "        name = artist_name\n",
    "        begin_date = pd.Timestamp(start_band_date).date()\n",
    "        area = artist_high_level['area']['name']\n",
    "\n",
    "        album_name = []\n",
    "        release_date = []\n",
    "\n",
    "        for album in first_albums:\n",
    "            album_name.append(album['title'])\n",
    "            release_date.append(album['first-release-date'])\n",
    "\n",
    "        album_name = [i for i in album_name if artist_name not in i]\n",
    "        albums = {artist_name:album_name}\n",
    "\n",
    "        return albums\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'FAILED: {artist_name}, {e}')\n",
    "        return None\n",
    "\n",
    "# this needs to point to csv's\n",
    "def update_backend(n_updates=5):\n",
    "    try:\n",
    "        data = pd.read_csv('band_unit_test.csv')\n",
    "        current_bands = data['name'].unique()\n",
    "        bands_to_update = np.setdiff1d(additional_bands, current_bands)[:n_updates]\n",
    "\n",
    "        bands_cleaned = [create_cleaned_artist(artist_name=artist) for artist in bands_to_update]\n",
    "        bands_cleaned = [i for i in bands_cleaned if i is not None]\n",
    "        cleaned_data = pd.concat([create_cleaned_artist(artist_name=artist) for artist in bands_to_update])\n",
    "        update = pd.concat([data, cleaned_data])\n",
    "        update.to_csv('BANDS.csv')\n",
    "\n",
    "        albums_update = {}\n",
    "        for artist in current_bands:\n",
    "            albums_update.update(create_album_dict(artist_name=artist))\n",
    "        \n",
    "        album_name_dict.update(albums_update)\n",
    "        \n",
    "        with open(\"app_data.py\", \"a\") as file:\n",
    "            file.write(f\"\\nmy_dict = {album_name_dict}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"BACKEND UPDATE FAILED: {e}\")\n",
    "        \n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'38 Special': ['Special Delivery',\n",
       "  'Rockin’ Into the Night',\n",
       "  'Wild‐Eyed Southern Boys',\n",
       "  'Special Forces',\n",
       "  'Tour de Force',\n",
       "  'Strength in Numbers',\n",
       "  'Rock & Roll Strategy',\n",
       "  'Bone Against Steel',\n",
       "  'Resolution',\n",
       "  'A Wild‐Eyed Christmas Night',\n",
       "  'Drivetrain',\n",
       "  '10 From 38',\n",
       "  'Flashback',\n",
       "  'Anthology',\n",
       "  'Christmas',\n",
       "  'The Very Best of the A&M Years (1977–1988)',\n",
       "  'Best Shots',\n",
       "  'Icon',\n",
       "  'Classics',\n",
       "  'Greatest Hits',\n",
       "  'Wild Eyed and Live!',\n",
       "  'Live at Sturgis',\n",
       "  'Extended Versions: The Encore Collection']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_album_dict(artist_name=additional_bands[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating rng dict to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_day = pd.DataFrame({\n",
    "    'date':list(rng_dict.keys()),\n",
    "    'idx':list(rng_dict.values())\n",
    "})\n",
    "\n",
    "reset_day.to_csv('~/Desktop/rock riddle/DAY_RESET.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_df = pd.DataFrame({\n",
    "    'artist': list(album_name_dict.keys()),\n",
    "    'albums': list(album_name_dict.values())\n",
    "})\n",
    "\n",
    "album_df.to_csv('~/Desktop/rock riddle/ALBUMS.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_backend(n_updates=5):\n",
    "    try:\n",
    "        # 1. update bands\n",
    "        data = pd.read_csv('band_unit_test.csv')\n",
    "        current_bands = data['name'].unique()\n",
    "        bands_to_update = np.setdiff1d(additional_bands, current_bands)[:n_updates]\n",
    "\n",
    "        bands_cleaned = [create_cleaned_artist(artist_name=artist) for artist in bands_to_update]\n",
    "        bands_cleaned = pd.concat([i for i in bands_cleaned if i is not None])\n",
    "        cleaned_artists = bands_cleaned['name'].unique()\n",
    "\n",
    "        update = pd.concat([data, bands_cleaned])\n",
    "        update.to_csv('~/Desktop/rock riddle/BANDS.csv', index=False)\n",
    "        \n",
    "        # 2. update albums\n",
    "        albums_existing = pd.read_csv('~/Desktop/rock riddle/backend/ALBUMS.csv')\n",
    "        album_frames = []\n",
    "        for artist in cleaned_artists:\n",
    "            try:\n",
    "                album_data = create_album_dict(artist_name=artist)\n",
    "                album_frame = pd.DataFrame({\n",
    "                    'artist': list(album_data.keys())[0],\n",
    "                    'albums': list(album_data.values())\n",
    "                })\n",
    "            except:\n",
    "                album_frame = None\n",
    "            \n",
    "            album_frames.append(album_frame)\n",
    "        \n",
    "        album_frames = pd.concat([frame for frame in album_frames if frame is not None])\n",
    "\n",
    "        albums_final = pd.concat([albums_existing, album_frames])\n",
    "        albums_final.to_csv('~/Desktop/rock riddle/backend/ALBUMS.csv', index=False)\n",
    "\n",
    "        # 3. update day indices \n",
    "        existing_days = pd.read_csv('~/Desktop/rock riddle/backend/DAY_RESET.csv')\n",
    "        final_day = existing_days['date'].values[-1]\n",
    "        range_dates = pd.date_range(\n",
    "            start=(pd.Timestamp(final_day).date() + pd.DateOffset(days=1)), end=(pd.Timestamp(final_day).date() + pd.DateOffset(days=album_frames.shape[0])).date(), freq='D')\n",
    "        \n",
    "        arr = np.array(range(existing_days.shape[0] + 1, existing_days.shape[0] + album_frames.shape[0] + 1))\n",
    "\n",
    "        np.random.shuffle(arr)\n",
    "\n",
    "        new_days = pd.DataFrame({\n",
    "            'date': [str(date.date()) for date in range_dates],\n",
    "            'idx': arr\n",
    "        })\n",
    "\n",
    "        final_days = pd.concat([existing_days, new_days])\n",
    "\n",
    "        final_days.to_csv('~/Desktop/rock riddle/backend/DAY_RESET.csv', index=False)\n",
    "\n",
    "        return final_days.sort_values('date')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"BACKEND UPDATE FAILED: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('~/Desktop/rock riddle/backend/DAY_RESET.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-25</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-26</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-28</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-08-18</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-08-19</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-08-20</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-08-21</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-08-22</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  idx\n",
       "0   2024-12-25   95\n",
       "1   2024-12-26   61\n",
       "2   2024-12-27  113\n",
       "3   2024-12-28    4\n",
       "4   2024-12-29   10\n",
       "..         ...  ...\n",
       "0   2025-08-18  239\n",
       "1   2025-08-19  241\n",
       "2   2025-08-20  240\n",
       "3   2025-08-21  237\n",
       "4   2025-08-22  238\n",
       "\n",
       "[241 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249,\n",
       "       250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262,\n",
       "       263, 264, 265, 266])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-08-17'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2025-08-18', '2025-08-19', '2025-08-20', '2025-08-21',\n",
       "               '2025-08-22', '2025-08-23', '2025-08-24', '2025-08-25',\n",
       "               '2025-08-26', '2025-08-27', '2025-08-28', '2025-08-29',\n",
       "               '2025-08-30', '2025-08-31', '2025-09-01', '2025-09-02',\n",
       "               '2025-09-03', '2025-09-04', '2025-09-05', '2025-09-06',\n",
       "               '2025-09-07', '2025-09-08', '2025-09-09', '2025-09-10',\n",
       "               '2025-09-11', '2025-09-12', '2025-09-13', '2025-09-14',\n",
       "               '2025-09-15', '2025-09-16', '2025-09-17', '2025-09-18',\n",
       "               '2025-09-19', '2025-09-20', '2025-09-21', '2025-09-22',\n",
       "               '2025-09-23', '2025-09-24', '2025-09-25', '2025-09-26',\n",
       "               '2025-09-27', '2025-09-28', '2025-09-29', '2025-09-30',\n",
       "               '2025-10-01'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_day = test['date'].values[-1]\n",
    "pd.date_range(start=(pd.Timestamp(final_day).date() + pd.DateOffset(days=1)), end=(pd.Timestamp(final_day).date() + pd.DateOffset(days=45)).date(), freq='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_country_dict = {\n",
    "    'Australia':'Australia',\n",
    "    'United States':'North America',\n",
    "    'United Kingdom':'Europe',\n",
    "    'England':'Europe',\n",
    "    'Canada':'North America',\n",
    "    'Germany':'Europe',\n",
    "    'Ireland':'Europe',\n",
    "    'Memphis':'North America',\n",
    "    'Netherlands':'Europe',\n",
    "    'Finland':'Europe',\n",
    "    'Brazil':'South America',\n",
    "    'Jamaica':'North America',\n",
    "    'Sweden':'Europe',\n",
    "    'New York':'North America',\n",
    "    'Boston':'North America'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df = pd.DataFrame({\n",
    "    'country': list(full_country_dict.keys()),\n",
    "    'continents': list(full_country_dict.values())\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df.to_csv('/Users/benstager/Desktop/rock riddle/backend/COUNTRIES.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
